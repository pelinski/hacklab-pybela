{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Collect dataset\n",
    "Connect the left and right pins of the potentiometer to the ground and 3.3V pins in Bela and the middle pin to the analog input A0. Run the `dataset-capture` project on Bela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniPyBela import Streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer=Streamer(ip=\"bela.local\")\n",
    "streamer.start_streaming(saving_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer.stop_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import pprint as pp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pyBela import Streamer\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = Streamer()\n",
    "raw = streamer.load_data_from_file(\"pot_var_stream__3.txt\")\n",
    "data = [data for buffer in raw for data in buffer[\"data\"]]\n",
    "\n",
    "class PotentiometerDataset(Dataset):\n",
    "    def __init__(self, data, seq_len=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # make len divisible by seq_len\n",
    "        data = data[:len(data) - (len(data) % seq_len)]\n",
    "        sequences = [data[i:i+seq_len] for i in range(0, len(data), seq_len)]\n",
    "\n",
    "        self.inputs = torch.tensor(sequences[:-1]).float().to(self.device)\n",
    "        self.outputs = torch.tensor(sequences[1:]).float().to(self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.inputs[i].unsqueeze(dim=1), self.outputs[i].unsqueeze(dim=1)\n",
    "    \n",
    "dataset = PotentiometerDataset(data, seq_len=32)\n",
    "_in, out = dataset.__getitem__(0)\n",
    "\n",
    "print(_in.shape, out.shape)\n",
    "\n",
    "\n",
    "# Split dataset\n",
    "train_count = int(0.9 * dataset.__len__())\n",
    "test_count = dataset.__len__() - train_count\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, (train_count, test_count)\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate the RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Apply the linear layer to get the final output\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "#model = RNN(input_size=1, hidden_size=64, out_size=1).to(device='cuda')\n",
    "#model = nn.RNN(input_size=1, hidden_size=12, num_layers=1).to(device='cuda')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleRNN(input_size=1, hidden_size=64, output_size=1).to(device=device)\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "print(\"Running on device: {}\".format(device))\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    print(\"█▓░ Epoch: {} ░▓█\".format(epoch))\n",
    "\n",
    "    # training loop\n",
    "    train_it_losses = np.array([])\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # (batch_size, seq_len, input_size)\n",
    "        data = data.to(device=device, non_blocking=True)\n",
    "        # (batch_size, seq_len, input_size)\n",
    "        targets = targets.to(device=device, non_blocking=True)\n",
    "        \n",
    "        \n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)  # lower memory footprint\n",
    "        out = model(data)\n",
    "        train_loss = torch.sqrt(criterion(out, targets))\n",
    "        train_it_losses = np.append(train_it_losses, train_loss.item())\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # test loop\n",
    "    test_it_losses = []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(test_loader)):\n",
    "        # (batch_size, seq_length, input_size)\n",
    "        data = data.to(device=device, non_blocking=True)\n",
    "        # (batch_size, seq_length, out_size)\n",
    "        targets = targets.to(device=device, non_blocking=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)  # using predict method to avoid backprop\n",
    "        test_loss = torch.sqrt(criterion(out, targets))\n",
    "        test_it_losses = np.append(\n",
    "            test_it_losses, test_loss.item())\n",
    "\n",
    "    losses = {\"train_loss\": train_it_losses.mean().round(\n",
    "        8), \"test_loss\": test_it_losses.mean().round(8)}\n",
    "    pp.pprint(losses, sort_dicts=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot predictions on test data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "input, target = test_dataset.__getitem__(5)\n",
    "\n",
    "output = model(input.unsqueeze(0))\n",
    "\n",
    "print(input.unsqueeze(0).shape, output.shape)\n",
    "print(input.shape, target.shape, output.shape)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(target.view(-1).detach().cpu(), label='True')\n",
    "plt.plot(output.view(-1).detach().cpu(), label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.ylim(0, 3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device='cpu')\n",
    "model.eval()\n",
    "script = torch.jit.script(model)\n",
    "script.save(\"bela-code/model.jit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.load(\"model.jit\") # check model is properly saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - deploy and run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
