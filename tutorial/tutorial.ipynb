{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pybela tutorial\n",
    "In this workshop we'll be using jupyter notebooks and python to:\n",
    "1. Record a dataset of potentiometer and piezo sensor values\n",
    "2. Train an RNN to predict those values\n",
    "3. Cross-compile and deploy the model to run in real-time in Bela\n",
    "\n",
    "Connect your Bela to the laptop and run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ssh-keyscan $BBB_HOSTNAME >> ~/.ssh/known_hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also import all the necessary python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pybela import Logger\n",
    "import asyncio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 – pybela basics\n",
    "\n",
    "[pybela](https://github.com/BelaPlatform/pybela/) allows sending data back and forth between python and Bela.\n",
    "\n",
    "For pybela to be able to communicate with Bela, there has to be a project running on the Bela. \n",
    "\n",
    "We have an example project in `/root/bela-code/pybela-basic`. Let's take a look at the cpp code.\n",
    "\n",
    "### c++ code\n",
    "The cpp code in `pybela-basics/render.cpp` reads the value of a potentiometer which controls the volume of a wave sound. The potentiometer value is stored in a `pot` variable which is defined in a special way so we can access it from python.\n",
    "\n",
    "You should connect a potentiometer to the Bela's analog input 0:\n",
    "\n",
    "![potentiometer](_fritzing/potentiometer.png)\n",
    "\n",
    "Let's take a look at the Watcher API in `pybela-basics/render.cpp`:\n",
    "\n",
    "\n",
    "The Watcher API in the Bela code allows \"watching\" variables in the Bela code so we can retrieve their values from python. First, we define the variables we want to watch this way:\n",
    "\n",
    "```cpp\n",
    "Watcher<float> pot(\"pot\"); // the \"pot\" variable is \"watched\"\n",
    "```\n",
    "\n",
    "In the `setup()` function, we initialize the Watcher:\n",
    "\n",
    "```cpp\n",
    "bool setup(BelaContext *context, void *userData) {\n",
    "\n",
    "  Bela_getDefaultWatcherManager()->getGui().setup(context->projectName);\n",
    "  Bela_getDefaultWatcherManager()->setup(\n",
    "      context->audioSampleRate); // set sample rate in watcher\n",
    "\n",
    "      ...\n",
    "```\n",
    "\n",
    "We need to tell the Watcher the rate at which we want to observe the variables. For that, we \"tick\" the Watcher clock in the `render()` function. Note that we only tick it at the analog rate, since \"pot\" is an analog variable (typicially read once per two audio frames):\n",
    "\n",
    "```cpp\n",
    "\n",
    "void render(BelaContext *context, void *userData) {\n",
    "\n",
    "  for (unsigned int n = 0; n < context->audioFrames; n++) {\n",
    "\n",
    "    uint64_t analogFramesElapsed = int((context->audioFramesElapsed + n) / 2);\n",
    "    Bela_getDefaultWatcherManager()->tick(\n",
    "        analogFramesElapsed); // tick the watcher clock\n",
    "\n",
    "    if (gAudioFramesPerAnalogFrame && !(n % gAudioFramesPerAnalogFrame)) {\n",
    "      pot = analogRead(context, n / gAudioFramesPerAnalogFrame, 0);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's now crosscompile this code and run it on the Bela.\n",
    "\n",
    "### xcompiling the cpp code \n",
    "\n",
    "To cross-compile the code, we use `cmake` and a cross-compilation toolchain. A cross-compilation toolchain tells `cmake` that even though we are compiling the code on our laptop, the code is meant to run on the Bela.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd bela-code/pybela-basic && cmake -S . -B build -DPROJECT_NAME=pybela-basic -DCMAKE_TOOLCHAIN_FILE=/sysroot/root/Bela/Toolchain.cmake\n",
    "!cd bela-code/pybela-basic && cmake --build build -j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now built an executable for the Bela, which is located at `bela-code/pybela-basic/build/pybela-basic`. Let's copy it to the Bela, along with the project files so we can access them from the Bela IDE, and the `waves.wav` file which is used by the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync -rvL --timeout 10 bela-code/pybela-basic/build/pybela-basic root@$BBB_HOSTNAME:Bela/projects/pybela-basic/\n",
    "!rsync -rvL --timeout 10 bela-code/pybela-basic/  --exclude=\"build\" root@$BBB_HOSTNAME:/root/Bela/projects/pybela-basic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it, open a terminal and ssh into the Bela and run the program:\n",
    "\n",
    "```bash\n",
    "ssh root@bela.local\n",
    "cd Bela/projects/pybela-basic && ./pybela-basic\n",
    "```\n",
    "(running this on the Jupyter notebook would block the cell and we need to be able to run the next cells!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python code\n",
    "Now we are ready to interact with the Bela code from python. First we import `pybela` and create a `Logger` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=Logger(ip=os.environ[\"BBB_HOSTNAME\"])\n",
    "logger.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Logger is connected to Bela. The Logger class allows us recording datasets locally in Bela and transferring them automatically to the host computer. \n",
    "\n",
    "Connect your headphones to the Bela audio output and run the cell below while you rotate the potentiometer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = logger.start_logging(\"pot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds, you can stop the logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.stop_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transfer is done, you can retrieve the logged data by reading the binary file in which it was saved. That binary file stores the data as timestamped buffers, which we are not interested on as we just want a continuous array of potentiometer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot\"], timestamp_mode=logger.get_prop_of_var(\"pot\", \"timestamp_mode\"))\n",
    "data = [data for _buffer in raw[\"buffers\"] for data in _buffer[\"data\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_sample_rate = logger.sample_rate/2\n",
    "\n",
    "plt.plot(np.arange(len(data)) / analog_sample_rate, data)\n",
    "plt.title('Pot Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 – potentiometers dataset capture\n",
    "\n",
    "We are now ready to record a dataset with two potentiometers. Connect the second potentiometer to your Bela:\n",
    "\n",
    "![potentiometers](_fritzing/potentiometer_2.png)\n",
    "\n",
    "\n",
    " We will be running the `dataset-capture` project. Now the first potentiometer controls the waveshape of an LFO and the second potentiometer, the volume of the sound.\n",
    "\n",
    "Let's start by cross-compiling the code and copying it to Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd bela-code/dataset-capture && cmake -S . -B build -DPROJECT_NAME=dataset-capture -DCMAKE_TOOLCHAIN_FILE=/sysroot/root/Bela/Toolchain.cmake\n",
    "!cd bela-code/dataset-capture && cmake --build build -j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync -rvL --timeout 10 bela-code/dataset-capture/build/dataset-capture root@$BBB_HOSTNAME:Bela/projects/dataset-capture/\n",
    "!rsync -rvL --timeout 10 bela-code/dataset-capture/  --exclude=\"build\" root@$BBB_HOSTNAME:/root/Bela/projects/dataset-capture/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the `dataset-capture` project on the Bela:\n",
    "\n",
    "```bash\n",
    "ssh root@bela.local\n",
    "cd Bela/projects/dataset-capture && ./dataset-capture\n",
    "```\n",
    "\n",
    "Feel free to play around with the potentiometer and the piezo sensor. You can also edit the code in the IDE and re-run the project.\n",
    "\n",
    "Once you're ready. You can record a dataset of potentiometer and piezo sensor values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=Logger(ip=os.environ[\"BBB_HOSTNAME\"])\n",
    "logger.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can time the length of your dataset using `asyncio.sleep(time_in_seconds)`. Note we are not using `time.sleep()` because it would block the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = logger.start_logging(variables=[\"pot1\", \"pot2\"])\n",
    "await asyncio.sleep(90)\n",
    "logger.stop_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot1_raw_data = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot1\"], timestamp_mode=logger.get_prop_of_var(\"pot1\", \"timestamp_mode\"))\n",
    "pot2_raw_data = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot2\"], timestamp_mode=logger.get_prop_of_var(\"pot2\", \"timestamp_mode\"))\n",
    "\n",
    "pot1_data = [data for _buffer in pot1_raw_data[\"buffers\"] for data in _buffer[\"data\"]]\n",
    "pot2_data = [data for _buffer in pot2_raw_data[\"buffers\"] for data in _buffer[\"data\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_sample_rate = logger.sample_rate/2\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.arange(len(pot1_data)) / analog_sample_rate, pot1_data)\n",
    "plt.title('Pot 1 Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Second subplot for pie_data\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.arange(len(pot2_data)) / analog_sample_rate, pot2_data)\n",
    "plt.title('Pot 2 Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - train model\n",
    "Now we are ready to train our model.\n",
    "We can generate a pytorch compatible dataset using the `SensorDataset` class. This class divides the data you recorded previously in sequences of 512 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "batch_size = 32\n",
    "\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, pot1_data, pot2_data, seq_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # make len divisible by seq_len\n",
    "        _len = min(len(pot1_data), len(pot2_data))\n",
    "        pot1_data = pot1_data[:_len - (_len % seq_len)]\n",
    "        pot2_data = pot2_data[:_len - (_len % seq_len)]\n",
    "\n",
    "        pot1_sequences = torch.tensor([pot1_data[i:i+seq_len] for i in range(0, len(pot1_data), seq_len)]).float().to(self.device)\n",
    "        pot2_sequences = torch.tensor([pot2_data[i:i+seq_len] for i in range(0, len(pot2_data), seq_len)]).float().to(self.device)\n",
    "        \n",
    "        self.inputs = torch.stack((pot1_sequences[:-1], pot2_sequences[:-1]), dim=2)\n",
    "        self.outputs = torch.stack((pot1_sequences[1:],pot2_sequences[1:]), dim=2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.inputs[i], self.outputs[i]\n",
    "    \n",
    "dataset = SensorDataset(pot1_data, pot2_data, seq_len)\n",
    "dataset_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a simple RNN with a hidden size of 64. We will use an SGD optimiser with a learning rate of 0.001 and use the mean square error as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate the RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Apply the linear layer to get the final output\n",
    "        out = self.fc(out)\n",
    "   \n",
    "        \n",
    "        return out\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RNN(input_size=2, hidden_size=64, output_size=2).to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test that the model has been properly defined with a dummy input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(5, 512, 2)\n",
    "model.forward(input).shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "epoch_losses = np.array([])\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    print(\">> Epoch: {} <<\".format(epoch))\n",
    "\n",
    "    # training loop\n",
    "    batch_losses = np.array([])\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(dataset_loader)):\n",
    "        # (batch_size, seq_len, input_size)\n",
    "        data = data.to(device=device, non_blocking=True)\n",
    "        # (batch_size, seq_len, input_size)\n",
    "        targets = targets.to(device=device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)  # lower memory footprint\n",
    "        out = model(data)\n",
    "        loss = torch.sqrt(criterion(out, targets))\n",
    "        batch_losses = np.append(batch_losses, loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_losses = np.append(epoch_losses, batch_losses.mean().round(4))\n",
    "\n",
    "    print(f'Loss: {epoch_losses[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the loss to see how the training went:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_epochs = range(1, epochs + 1)\n",
    "\n",
    "plt.scatter(x_epochs, epoch_losses, marker='o')\n",
    "plt.plot(x_epochs, epoch_losses, linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(x_epochs)  # Ensure x-axis has integer values for each epoch\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** If you get a `RuntimeError: could not create a primitive descriptor for a matmul primitive` error here --> check the `readme-silicon.md`. This error seems to happen when training on a jupyter notebook running on a docker container on Mac M1/M2. In the `readme-silicon.md` there are instructions for running the notebook locally (in your laptop, not in the container) so that this error doesn't appear.\n",
    "\n",
    "Let's make sure the model trained correctly by visualising some of the predictions in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random indexes for plotting\n",
    "num_examples = 4\n",
    "random_indexes = np.random.choice(len(dataset), size=num_examples, replace=False)\n",
    "\n",
    "# Calculate the number of rows for the subplots\n",
    "num_rows = num_examples\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(12, 3 * num_rows))\n",
    "\n",
    "# Loop through random indexes and plot predictions\n",
    "for idx, ax_row in zip(random_indexes, axes):\n",
    "    input, target = dataset.__getitem__(idx)\n",
    "    output = model(input.unsqueeze(0))\n",
    "    \n",
    "    # Plot for the first dimension in the first column\n",
    "    ax_row[0].plot(target[:, 0].detach().cpu(), label='Target')\n",
    "    ax_row[0].plot(output[0, :, 0].detach().cpu(), label='Predictions')\n",
    "    ax_row[0].set_xlabel('Time')\n",
    "    ax_row[0].set_ylabel('Value')\n",
    "    ax_row[0].legend()\n",
    "    ax_row[0].set_ylim(0, 3)\n",
    "    ax_row[0].set_title(f'Figure for Index {idx} - Pot 1')\n",
    "    \n",
    "    # Plot for the second dimension in the second column\n",
    "    ax_row[1].plot(target[:, 1].detach().cpu(), label='Target')\n",
    "    ax_row[1].plot(output[0, :, 1].detach().cpu(), label='Prediction')\n",
    "    ax_row[1].set_xlabel('Time')\n",
    "    ax_row[1].set_ylabel('Value')\n",
    "    ax_row[1].legend()\n",
    "    ax_row[1].set_title(f'Figure for Index {idx} - Pot 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're ready, save the model so that we can export it into Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device='cpu')\n",
    "model.eval()\n",
    "script = torch.jit.script(model)\n",
    "path = \"bela-code/inference/model.jit\"\n",
    "script.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.load(path) # check model is properly saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - deploy and run\n",
    "\n",
    "The cell below will cross-compile and deploy the project to Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd bela-code/inference && cmake -S . -B build -DPROJECT_NAME=inference -DCMAKE_TOOLCHAIN_FILE=/sysroot/root/Bela/Toolchain.cmake\n",
    "!cd bela-code/inference && cmake --build build -j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync -rvL --timeout 10 bela-code/inference/build/inference root@$BBB_HOSTNAME:Bela/projects/inference/\n",
    "!rsync -rvL --timeout 10 bela-code/inference/  --exclude=\"build\" root@$BBB_HOSTNAME:/root/Bela/projects/inference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once deployed, you can run it from the Bela terminal (which you can access from your regular terminal typing `ssh root@bela.local`) by typing:\n",
    "```bash\n",
    "cd Bela/projects/inference\n",
    "./pot-inference -m model.jit\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
