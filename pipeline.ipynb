{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pybela-pytorch-xc-tutorial tutorial\n",
    "In this workshop we'll be using jupyter notebooks and python to:\n",
    "1. Record a dataset of potentiometer sensor values\n",
    "2. Train a TCN to predict those values\n",
    "3. Cross-compile and deploy the model to run in real-time in Bela\n",
    "\n",
    "Connect your Bela to the laptop and run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'hacklab (Python 3.9.12)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/pelinski/Dropbox/phd/projects/sonar-hacklab/hacklab/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "! ssh-keyscan $BBB_HOSTNAME >> ~/.ssh/known_hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also import all the necessary python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pybela import Logger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python code\n",
    "Now we are ready to interact with the Bela code from python. First we import `pybela` and create a `Logger` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=Logger(ip=os.environ[\"BBB_HOSTNAME\"])\n",
    "logger.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Logger is connected to Bela. The Logger class allows us recording datasets locally in Bela and transferring them automatically to the host computer. \n",
    "\n",
    "Connect your headphones to the Bela audio output and run the cell below while you rotate the potentiometer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = logger.start_logging(\"in\")\n",
    "logger.wait(10*60)  # wait for 10 minutes\n",
    "logger.stop_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot\"], timestamp_mode=logger.get_prop_of_var(\"pot\", \"timestamp_mode\"))\n",
    "data = [data for _buffer in raw[\"buffers\"] for data in _buffer[\"data\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_sample_rate = logger.sample_rate/2\n",
    "\n",
    "plt.plot(np.arange(len(data)) / analog_sample_rate, data)\n",
    "plt.title('Pot Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 â€“ potentiometers dataset capture\n",
    "\n",
    "We are now ready to record a dataset with two potentiometers. Connect the second potentiometer to your Bela:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"_fritzing/potentiometer_2.png\" alt=\"potentiometer\" width=\"300\"/>\n",
    "</p>\n",
    "\n",
    " We will be running the `dataset-capture` project. Now the first potentiometer controls the waveshape of an LFO and the second potentiometer, the volume of the sound.\n",
    "\n",
    "Let's start by cross-compiling the code and copying it to Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd bela-code/dataset-capture && cmake -S . -B build -DPROJECT_NAME=dataset-capture -DCMAKE_TOOLCHAIN_FILE=/sysroot/root/Bela/Toolchain.cmake\n",
    "!cd bela-code/dataset-capture && cmake --build build -j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync -rvL --timeout 10 bela-code/dataset-capture/build/dataset-capture root@$BBB_HOSTNAME:Bela/projects/dataset-capture/\n",
    "!rsync -rvL --timeout 10 bela-code/dataset-capture/  --exclude=\"build\" root@$BBB_HOSTNAME:/root/Bela/projects/dataset-capture/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the `dataset-capture` project on the Bela:\n",
    "\n",
    "```bash\n",
    "ssh root@bela.local\n",
    "cd Bela/projects/dataset-capture && ./dataset-capture\n",
    "```\n",
    "\n",
    "Feel free to play around with the potentiometer and the piezo sensor. You can also edit the code in the IDE and re-run the project.\n",
    "\n",
    "Once you're ready. You can record a dataset of potentiometer and piezo sensor values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=Logger(ip=os.environ[\"BBB_HOSTNAME\"])\n",
    "logger.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can time the length of your dataset using `asyncio.sleep(time_in_seconds)`. Note we are not using `time.sleep()` because it would block the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = logger.start_logging(variables=[\"pot1\", \"pot2\"])\n",
    "await asyncio.sleep(90)\n",
    "logger.stop_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot1_raw_data = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot1\"], timestamp_mode=logger.get_prop_of_var(\"pot1\", \"timestamp_mode\"))\n",
    "pot2_raw_data = logger.read_binary_file(\n",
    "        file_path=file_paths[\"local_paths\"][\"pot2\"], timestamp_mode=logger.get_prop_of_var(\"pot2\", \"timestamp_mode\"))\n",
    "\n",
    "pot1_data = [data for _buffer in pot1_raw_data[\"buffers\"] for data in _buffer[\"data\"]]\n",
    "pot2_data = [data for _buffer in pot2_raw_data[\"buffers\"] for data in _buffer[\"data\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_sample_rate = logger.sample_rate/2\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.arange(len(pot1_data)) / analog_sample_rate, pot1_data)\n",
    "plt.title('Pot 1 Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Second subplot for pie_data\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.arange(len(pot2_data)) / analog_sample_rate, pot2_data)\n",
    "plt.title('Pot 2 Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - train model\n",
    "Now we are ready to train our model.\n",
    "We can generate a pytorch compatible dataset using the `SensorDataset` class. This class divides the data you recorded previously in sequences of 512 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "batch_size = 32\n",
    "target_windows = 1\n",
    "\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, pot1_data, pot2_data, seq_len, target_windows):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # make len divisible by seq_len\n",
    "        _len = min(len(pot1_data), len(pot2_data))\n",
    "        _len = _len - (_len % seq_len)\n",
    "        pot1_data, pot2_data = pot1_data[:_len], pot2_data[:_len]\n",
    "        \n",
    "        pot1_sequences = torch.FloatTensor([pot1_data[i:i+seq_len] for i in range(0, len(pot1_data), seq_len)])\n",
    "        pot2_sequences = torch.FloatTensor([pot2_data[i:i+seq_len] for i in range(0, len(pot2_data), seq_len)])\n",
    "\n",
    "        self.inputs = torch.stack((pot1_sequences[:-target_windows], pot2_sequences[:-target_windows]), dim=2).to(self.device)\n",
    "        outputs=[]\n",
    "        for idx in range(1, len(pot1_sequences)-target_windows+1):\n",
    "            tgt_seq = torch.stack((pot1_sequences[idx:target_windows+idx].flatten(), pot2_sequences[idx:target_windows+idx].flatten()), dim=1)\n",
    "            outputs.append(tgt_seq)\n",
    "        self.outputs = torch.stack(outputs).to(self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.inputs[i], self.outputs[i]\n",
    "    \n",
    "dataset = SensorDataset(pot1_data, pot2_data, seq_len, target_windows)\n",
    "dataset_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a TCN. We will use an Adam optimiser with a learning rate of 0.001 and use the mean square error as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    \"\"\"Layer that removes trailing values to ensure causality in the TCN.\"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    \"\"\"A single temporal block in a TCN, with dilated causal convolutions and residual connections.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    \"\"\"A Temporal Convolutional Network (TCN) made up of multiple temporal blocks.\"\"\"\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2, upsample_factor=3):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        self.upsample_factor = upsample_factor  # Upsample factor as a parameter\n",
    "        \n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers.append(TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                        padding=(kernel_size-1) * dilation_size, dropout=dropout))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Upsample layer to increase sequence length by the upsample factor\n",
    "        self.upsample_layer = nn.ConvTranspose1d(num_channels[-1], num_channels[-1], kernel_size=self.upsample_factor, stride=self.upsample_factor)\n",
    "        \n",
    "        # Output layer to map back to the input feature size\n",
    "        self.output_layer = nn.Conv1d(num_channels[-1], num_inputs, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch_size, sequence_len, feature_size]\n",
    "        x = x.transpose(1, 2)  # Change shape to [batch_size, feature_size, sequence_len]\n",
    "        y = self.network(x)\n",
    "        \n",
    "        # Upsample the sequence length by the upsample factor\n",
    "        y = self.upsample_layer(y)\n",
    "        \n",
    "        # Map back to the original feature size\n",
    "        y = self.output_layer(y)  \n",
    "        y = y.transpose(1, 2)  # Change shape back to [batch_size, sequence_len*upsample_factor, feature_size]\n",
    "        return y\n",
    "\n",
    "\n",
    "batch_size, sequence_len, feature_size = 32, 512, 2\n",
    "upsample_factor = target_windows  # Define the upsample factor\n",
    "model = TemporalConvNet(num_inputs=feature_size, num_channels=[16, 32, 16], kernel_size=3, dropout=0.2, upsample_factor=upsample_factor)\n",
    "\n",
    "# Create a random tensor of shape [batch_size, sequence_len, feature_size]\n",
    "x = torch.randn(batch_size, sequence_len, feature_size)\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(x)\n",
    "\n",
    "print(output.shape)  # Output shape should be [batch_size, sequence_len*upsample_factor, feature_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "epoch_losses = np.array([])\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    print(\">> Epoch: {} <<\".format(epoch))\n",
    "\n",
    "    # training loop\n",
    "    batch_losses = np.array([])\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(dataset_loader)):\n",
    "        # (batch_size, seq_len, input_size)\n",
    "        data = data.to(device=device, non_blocking=True)\n",
    "        # (batch_size, seq_len, input_size)\n",
    "        targets = targets.to(device=device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)  # lower memory footprint\n",
    "        out = model(data)\n",
    "        loss = torch.sqrt(criterion(out, targets))\n",
    "        batch_losses = np.append(batch_losses, loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_losses = np.append(epoch_losses, batch_losses.mean().round(4))\n",
    "\n",
    "    print(f'Loss: {epoch_losses[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the loss to see how the training went:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_epochs = range(1, epochs + 1)\n",
    "\n",
    "plt.scatter(x_epochs, epoch_losses, marker='o')\n",
    "plt.plot(x_epochs, epoch_losses, linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(x_epochs)  # Ensure x-axis has integer values for each epoch\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the model trained correctly by visualising some of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random indexes for plotting\n",
    "num_examples = 4\n",
    "random_indexes = np.random.choice(len(dataset), size=num_examples, replace=False)\n",
    "\n",
    "# Calculate the number of rows for the subplots\n",
    "num_rows = num_examples\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(12, 3 * num_rows))\n",
    "\n",
    "# Loop through random indexes and plot predictions\n",
    "for idx, ax_row in zip(random_indexes, axes):\n",
    "    input, target = dataset.__getitem__(idx)\n",
    "    output = model(input.unsqueeze(0))\n",
    "    \n",
    "    # Plot for the first dimension in the first column\n",
    "    ax_row[0].plot(target[:, 0].detach().cpu(), label='Target')\n",
    "    ax_row[0].plot(output[0, :, 0].detach().cpu(), label='Predictions')\n",
    "    ax_row[0].set_xlabel('Time')\n",
    "    ax_row[0].set_ylabel('Value')\n",
    "    ax_row[0].legend()\n",
    "    ax_row[0].set_ylim(0, 3)\n",
    "    ax_row[0].set_title(f'Figure for Index {idx} - Pot 1')\n",
    "    \n",
    "    # Plot for the second dimension in the second column\n",
    "    ax_row[1].plot(target[:, 1].detach().cpu(), label='Target')\n",
    "    ax_row[1].plot(output[0, :, 1].detach().cpu(), label='Prediction')\n",
    "    ax_row[1].set_xlabel('Time')\n",
    "    ax_row[1].set_ylabel('Value')\n",
    "    ax_row[1].legend()\n",
    "    ax_row[1].set_title(f'Figure for Index {idx} - Pot 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're ready, save the model so that we can export it into Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device='cpu')\n",
    "model.eval()\n",
    "script = torch.jit.script(model)\n",
    "path = \"bela-code/inference/model.jit\"\n",
    "script.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.load(path) # check model is properly saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - deploy and run\n",
    "\n",
    "The cell below will cross-compile and deploy the project to Bela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd bela-code/inference && cmake -S . -B build -DPROJECT_NAME=inference -DCMAKE_TOOLCHAIN_FILE=/sysroot/root/Bela/Toolchain.cmake\n",
    "!cd bela-code/inference && cmake --build build -j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync -rvL --timeout 10 bela-code/inference/build/inference root@$BBB_HOSTNAME:Bela/projects/inference/\n",
    "!rsync -rvL --timeout 10 bela-code/inference/  --exclude=\"build\" root@$BBB_HOSTNAME:/root/Bela/projects/inference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once deployed, you can run it from the Bela terminal (which you can access from your regular terminal typing `ssh root@bela.local`) by typing:\n",
    "```bash\n",
    "cd Bela/projects/inference\n",
    "./inference -m model.jit\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacklab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
